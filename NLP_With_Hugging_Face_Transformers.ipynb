{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CztodpmQM11q"
      },
      "source": [
        "# Let's try HuggingFace Transformers NLP Pipelines!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dtAhiTAMmYN",
        "outputId": "2d48c70a-faed-4244-84a8-853ece1504b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3g0V_WTMpwB",
        "outputId": "e6053331-54d5-4f51-e0f6-502c7f6b3858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Artificial Intelligence will replace humans in the future',\n",
              " 'labels': ['technology', 'need', 'business', 'education'],\n",
              " 'scores': [0.9194765090942383,\n",
              "  0.072819784283638,\n",
              "  0.005830238573253155,\n",
              "  0.0018734720069915056]}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"Artificial Intelligence will replace humans in the future\",\n",
        "    candidate_labels=[\"education\", \"need\", \"business\", \"technology\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwkn1wZaNCxn",
        "outputId": "7c13fd87-7821-426f-8e87-bf262e5c148f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Artificial Intelligence will replace humans in the future, but they won't replace us.\\n\\nOn his YouTube channel, Google chief business officer Sundar Pichai (via Bloomberg) shared with us some more specifics regarding the future of AI -- the\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"Artificial Intelligence will replace humans in the future\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpcSkDJS61O6",
        "outputId": "fb9c2c35-2660-4231-f867-ed4afcb61e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drVV_RinNMws",
        "outputId": "2bad19a3-fda5-42fe-c5e9-de662452ca8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Artificial Intelligence will replace humans in the future. And because we are smart, we should be smart enough, too.\\n\\n\\n\\nHere's how people will look after smart things, and they won't look after stupid things or have a bad\"},\n",
              " {'generated_text': 'Artificial Intelligence will replace humans in the future.\\n\\n\\n\\n\\nThe AI will be coming in a variety of different colors and colors with different levels of accuracy. The design of artificial intelligence, the AI, or even computers, is very simple'},\n",
              " {'generated_text': 'Artificial Intelligence will replace humans in the future. With more than half the world’s population, computers will grow to be able to learn what was said before.\\n\\n\\n\\n\\nThe robots (like Siri, Siri, Cortana and other'},\n",
              " {'generated_text': 'Artificial Intelligence will replace humans in the future – it could become even bigger and will be capable of becoming the driving force for everything else.\\n\\n\\n\\n\\n\\n\\nIn a blog post titled “A Deep Dive into AI by Adam Davidson'},\n",
              " {'generated_text': 'Artificial Intelligence will replace humans in the future, according to a report from the BBC, with robots as soon as possible.\\n\\n\\n\\nThe report suggests AI could replace human-level computers in the wake of changes in current computer technologies, the'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"Artificial Intelligence will replace humans in the future\",\n",
        "    max_length=50,\n",
        "    num_return_sequences=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ab97He7Dd0k",
        "outputId": "aecbc889-bf02-441a-9451-b8446129fcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.24218778312206268,\n",
              "  'token': 143,\n",
              "  'token_str': ' any',\n",
              "  'sequence': 'in the future Artificial Intelligence will replace any human.'},\n",
              " {'score': 0.15689757466316223,\n",
              "  'token': 7945,\n",
              "  'token_str': ' ordinary',\n",
              "  'sequence': 'in the future Artificial Intelligence will replace ordinary human.'},\n",
              " {'score': 0.10553957521915436,\n",
              "  'token': 5,\n",
              "  'token_str': ' the',\n",
              "  'sequence': 'in the future Artificial Intelligence will replace the human.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"in the future Artificial Intelligence will replace <mask> human.\", top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-uxwPRKDhpB",
        "outputId": "a7e9144a-1977-4138-d10a-3858a4bbe02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9965387,\n",
              "  'word': 'Arya Pratama Putra',\n",
              "  'start': 5,\n",
              "  'end': 23},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9953444,\n",
              "  'word': 'Batam State Polytechnic',\n",
              "  'start': 50,\n",
              "  'end': 73},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.999736,\n",
              "  'word': 'Indonesia',\n",
              "  'start': 88,\n",
              "  'end': 97},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99836177,\n",
              "  'word': 'Google',\n",
              "  'start': 121,\n",
              "  'end': 127}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"I am Arya Pratama Putra and I am a Student at the Batam State Polytechnic and I live in Indonesia and now I also work at Google.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SbkDlwfDlF5",
        "outputId": "b7d0475e-1501-47a9-a23a-1b9f8b625b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jawaban: Southeast Asian continent\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"Indonesia is an archipelagic country located on the Southeast Asian continent and has 38 provinces, one of which is the Riau Islands province which is located near the South China Sea.\"\n",
        "question = \"Where is Indonesia located?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3IZcIeAE41r",
        "outputId": "e1612d73-7072-4c61-869c-bfafaaef5d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998351335525513}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"The product was delivered very quickly and the service was very good.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSjHIImDptH",
        "outputId": "5d9297a2-0d6f-4105-b240-ff76e05d8bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Pendidikan adalah hak setiap individu dan tanggung jawab bersama . Kita semua memiliki peran dalam mewujudkan pendidikan yang berkualitas . Pendidikahan    dapat bersaing dengan negara-negara lainnya .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Melakukan revisi terhadap kurikulum merdeka dengan memikirkan aspek aspek yang disebutkan diatas harus segera dilakukan agar tidak ketinggalan zaman dan dapat bersaing dengan negara-negara lainnya. Pendidikan adalah hak setiap individu dan tanggung jawab bersama. Kita semua memiliki peran dalam mewujudkan pendidikan yang berkualitas. Pemerintah perlu mengambil langkah-langkah konkret untuk memperbaiki kualitas pendidikan, sementara masyarakat, khususnya orang tua dan guru, perlu memberikan dukungan penuh terhadap upaya tersebut. Mari bersama-sama kita berinvestasi pada pendidikan untuk menciptakan generasi penerus bangsa yang cerdas, kreatif, dan berkarakter.Pentingnya peran orang tua: Orang tua memiliki peran yang sangat penting dalam memberikan dukungan dan motivasi kepada anak dalam meraih cita-citanya.Peran teknologi: Teknologi dapat menjadi alat yang sangat berguna dalam meningkatkan kualitas pembelajaran, namun perlu dimanfaatkan secara bijak.Keterlibatan masyarakat: Masyarakat luas juga memiliki peran penting dalam mendukung upaya peningkatan kualitas pendidikan, misalnya dengan memberikan donasi atau menjadi relawan.Pentingnya pendidikan karakter: Selain penguasaan ilmu pengetahuan, pendidikan karakter juga sangat penting untuk membentuk generasi muda yang berakhlak mulia. Mari bersama - sama wujudkan Indonesia Emas 2045\n",
        "\n",
        "\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxr6a3YYDtmL",
        "outputId": "b80b5849-99d7-48a8-bf3e-428d664c5240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today I want to eat fried rice and have iced tea\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_id_to_en\", model=\"Helsinki-NLP/opus-mt-id-en\")\n",
        "\n",
        "text_to_translate = \"Hari ini aku ingin makan nasi goreng dan minum es teh\"\n",
        "result = translator(text_to_translate)\n",
        "\n",
        "print(result[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vbYVRh2bn4y"
      },
      "source": [
        "# Analisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPnbUWgabrs8"
      },
      "source": [
        "- Zero-Shot Classification\n",
        "Merupakan jenis klasifikasi dengan metode Zero-Shot yang dimana metode ini mengklasifikasi teks ke dalam label yang diberikan sesuai dengan kategorinya dan semakin mendekati 1 berarti semakin akurat, metode ini mencoba menghubungkan konsep dengan hubungan kata - kata\n",
        "- Jawaban akan pertanyaan yang dijawab oleh model tergantung dari konteks yang kita masukkan semakin relevan konteks yang kita masukkin semakin akurat model memberikan jawaban\n",
        "- generator (\"text-generation\") dapat melakukan fungsi untuk melatih model untuk menghasilkan prediksi kata - kata yang logis dengan teks yang telah kita masukkin sebelumnya\n",
        "- distilgpt2 adalah model yang bisa menghasilkan kalimat lanjutan dari kalimat yang kita masukkin dan kalimat yang dihasilkan juga berbeda - beda dan disini saya juga bisa menentukan maksimun token yang akan dihasilkan dan berapa banyak kalimat yang mau dihasilkan\n",
        "- unmasker = pipeline(\"fill-mask\") model ini dapat memprediksi kata yang bisa mengisi kalimat yang kosong dalam contoh yang saya buat saya memprediksi 3 kata yang mungkin bisa mengisi kekosongan kalimat berikut \"in the future Artificial Intelligence will replace <mask> human.\"\n",
        "- ner adalah fungsi yang dapat mengidentifikasi entitas di dalam text yang saya masukkin lalu mengelompokkan jenis entitas yang terdapat di dalam text\n",
        "- \"question-answering\" merupakan fungsi yang dapat menjawab pertanyaan dari context yang kita berikan dan jawabannya akan sesuai context yang dimasukkan\n",
        "- Classifier (\"sentiment-analysis\") adalah fungsi yang dapat menganalisa sentimen dari kalimat yang saya masukkin dan hasilnya akan diklasifikasikan menjadi label positive ataupu negatif dan apabila scorenya mendekati 1 semakin kuat sentiment nya positive\n",
        "- Summarizer merupakan fungsi untuk meringkas teks dari konteks teks yang kita masukkin\n",
        "- Translator merupakan fungsi untuk menerjemahkan bahasa dari teks dan bahasanya bisa kita masukkin di sini saya coba menerjemahkan teks bahasa indonesia lalu ditampilkan ke bahasa inggris\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}